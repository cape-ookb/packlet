#!/usr/bin/env npx tsx

/**
 * analyze-document.ts
 *
 * Example demonstrating the analyze pipeline.
 * Runs AST analysis on a document and prints the complete processing context.
 *
 * Usage:
 *   npx tsx examples/analyze-document.ts
 */

import { readFileSync } from 'fs';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';
import { runAnalyzePipeline } from '../lib/index';
import { withDefaults } from '../lib/default-config';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// Load a test fixture for demonstration
const documentPath = join(__dirname, '../tests/fixtures/mixed-content.md');
const documentContent = readFileSync(documentPath, 'utf-8');
const documentTitle = 'mixed-content.md';

// Configure options
const options = withDefaults({
  maxTokens: 512,
  minTokens: 64,
  overlapSentences: 1
});

console.log('üîç Document Analysis Pipeline Demo');
console.log('==================================\n');

console.log(`üìÑ Analyzing: ${documentTitle}`);
console.log(`üìä Document size: ${documentContent.length} characters\n`);

// Show a preview of the document content
console.log('üìã Document Preview:');
console.log('--------------------');
const preview = documentContent.split('\n').slice(0, 10).join('\n');
console.log(preview);
if (documentContent.split('\n').length > 10) {
  console.log('... (content truncated for preview)');
}
console.log();

// Run the analyze pipeline
console.log('‚öôÔ∏è  Running Analysis Pipeline...\n');
const startTime = performance.now();
const result = runAnalyzePipeline(documentContent, documentTitle, options);
const endTime = performance.now();

console.log(`‚úÖ Analysis completed in ${(endTime - startTime).toFixed(2)}ms\n`);

// Display the complete context result
console.log('üìä Complete Processing Context:');
console.log('==============================\n');

// Source information
console.log('üè∑Ô∏è  Source Information:');
console.log(`   Title: ${result.source.title}`);
console.log(`   Length: ${result.source.length} characters`);
console.log(`   Tokens: ${result.source.tokens}`);
console.log(`   Estimated chunks: ${result.source.estimatedChunks}`);
console.log();

// Options used
console.log('‚öôÔ∏è  Processing Options:');
console.log(`   Max tokens: ${result.options.maxTokens}`);
console.log(`   Min tokens: ${result.options.minTokens}`);
console.log(`   Overlap sentences: ${result.options.overlapSentences}`);
console.log(`   Breadcrumb mode: ${result.options.breadcrumbMode}`);
console.log(`   Target tokens: ${result.options.targetTokens || 'auto'}`);
console.log();

// Timer information
console.log('‚è±Ô∏è  Timing Information:');
console.log(`   Start time: ${result.timer.startTime.toFixed(2)}ms`);
console.log(`   End time: ${result.timer.endTime?.toFixed(2)}ms`);
console.log(`   Duration: ${result.timer.durationMs?.toFixed(2)}ms`);
console.log();

// Processing stage
console.log('üîÑ Processing Stage:');
console.log(`   Current stage: ${result.stage}`);
console.log();

// AST information
console.log('üå≥ AST Information:');
if (result.ast) {
  console.log(`   Type: ${result.ast.type}`);
  console.log(`   Children: ${result.ast.children?.length || 0} top-level nodes`);

  // Show AST node types
  if (result.ast.children) {
    const nodeTypes = result.ast.children.map(child => child.type);
    const typeCounts = nodeTypes.reduce((acc, type) => {
      acc[type] = (acc[type] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);

    console.log('   Node type distribution:');
    Object.entries(typeCounts).forEach(([type, count]) => {
      console.log(`     - ${type}: ${count}`);
    });
  }
} else {
  console.log('   AST: Not available');
}
console.log();

// Structure analysis
console.log('üèóÔ∏è  Structure Analysis:');
if (result.structure) {
  console.log(`   Headings: ${result.structure.headingCount}`);
  console.log(`   Paragraphs: ${result.structure.paragraphCount}`);
  console.log(`   Code blocks: ${result.structure.codeBlockCount}`);
  console.log(`   Lists: ${result.structure.listCount}`);
  console.log(`   Tables: ${result.structure.tableCount}`);
} else {
  console.log('   Structure: Not available');
}
console.log();

// Detailed structure analysis
console.log('üî¨ Detailed Structure Analysis:');
if (result.structure) {
  console.log('   Heading levels:');
  Object.entries(result.structure.headingLevels).forEach(([level, count]) => {
    console.log(`     - H${level}: ${count}`);
  });

  console.log(`   Max nesting depth: ${result.structure.maxNestingDepth}`);
  console.log(`   Links: ${result.structure.linkCount}`);
  console.log(`   Images: ${result.structure.imageCount}`);
  console.log(`   Blockquotes: ${result.structure.blockquoteCount}`);
  console.log(`   Horizontal rules: ${result.structure.horizontalRuleCount}`);
  console.log(`   Has frontmatter: ${result.structure.hasFrontmatter}`);
  console.log(`   Has table of contents: ${result.structure.hasTableOfContents}`);

  if (result.structure.avgParagraphLength) {
    console.log(`   Avg paragraph length: ${result.structure.avgParagraphLength} chars`);
  }
}
console.log();

// What's NOT included (since this is analysis-only)
console.log('‚ùå Not Included (Analysis Pipeline Only):');
console.log(`   Nodes: ${result.nodes ? 'Available' : 'Not generated'}`);
console.log(`   Chunks: ${result.chunks ? 'Available' : 'Not generated'}`);
console.log(`   Stats: ${result.stats ? 'Available' : 'Not generated'}`);
console.log(`   Metrics: ${result.metrics ? 'Partial' : 'Not generated'}`);
console.log();

// Context fields summary
console.log('üìã Complete Context Fields:');
console.log('   ‚úÖ source (document info & metrics)');
console.log('   ‚úÖ options (processing configuration)');
console.log('   ‚úÖ timer (performance timing)');
console.log('   ‚úÖ stage (processing stage)');
console.log('   ‚úÖ ast (parsed markdown tree)');
console.log('   ‚úÖ structure (document structure stats)');
console.log('   ‚ùå nodes (not generated in analyze pipeline)');
console.log('   ‚ùå chunks (not generated in analyze pipeline)');
console.log('   ‚ùå stats (not generated in analyze pipeline)');
console.log();

console.log('üéØ Use Cases for Analysis Pipeline:');
console.log('  ‚Ä¢ Quick document structure inspection');
console.log('  ‚Ä¢ Debugging markdown parsing issues');
console.log('  ‚Ä¢ Getting document metrics without chunking');
console.log('  ‚Ä¢ Testing AST analysis in isolation');
console.log('  ‚Ä¢ Performance testing (fast, no chunking overhead)');
console.log();

console.log('üí° Next Steps:');
console.log('  ‚Ä¢ Use runFullPipeline() for complete chunking');
console.log('  ‚Ä¢ Use individual pipeline steps for custom workflows');
console.log('  ‚Ä¢ Examine result.ast for detailed AST inspection');
console.log('  ‚Ä¢ Check result.structure for document composition');

// Raw JSON output option
const showRawJSON = process.argv.includes('--json');
if (showRawJSON) {
  console.log('\nüîß Raw JSON Output:');
  console.log('===================');
  delete result.ast;
  delete result.source.content;
  console.log(JSON.stringify(result, null, 2));
} else {
  console.log('\n‚ú® Analysis complete! Use --json flag to see raw JSON output.');
}
